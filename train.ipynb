{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os                                    # for working with files\n",
    "import time                                  # for time-related functions\n",
    "import torch                                 # for the Pytorch module\n",
    "from torch import nn                         # for creating neural networks \n",
    "from torch import optim                      # for optimization algorithms.\n",
    "from torch.utils.data import DataLoader      # for dataloaders\n",
    "from torchvision import transforms           # for transforming images into tensors\n",
    "from torchvision import models               # for pre-trained models\n",
    "from torchvision.datasets import ImageFolder # for working with classes and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset path\n",
    "data_path = \"dataset/dataset\"\n",
    "train_path = data_path + \"/train\"\n",
    "valid_path = data_path + \"/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transforms\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = ImageFolder(train_path, transform=data_transforms[\"train\"])\n",
    "valid_data = ImageFolder(valid_path, transform=data_transforms[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data shape\n",
    "shape = train_data[0][0].shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size\n",
    "# Scale according to System Memory(CPU) or GPU Memory(GPU)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set num_workers and pin_memory \n",
    "# Scale according to System Memory\n",
    "n_ws = 4\n",
    "p_m = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True, num_workers=n_ws, pin_memory=p_m)\n",
    "valid_loader = DataLoader(valid_data, batch_size, shuffle=True, num_workers=n_ws, pin_memory=p_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the device to use for processing\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Set cuDNN to benchmark multiple convolution algorithms and select the fastest\n",
    "# only applicable if a CUDA device is selected for processing\n",
    "if (device.type == \"cuda\"):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EfficientNetV2-S model\n",
    "model = models.efficientnet_v2_s(weights=\"DEFAULT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of features in the last layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in train data\n",
    "num_clss = len(train_data.classes)\n",
    "num_clss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the last fully connected layer with a new one\n",
    "model.fc = nn.Linear(num_ftrs, num_clss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the metrics\n",
    "current_epoch = 0\n",
    "train_loss = 0.0\n",
    "valid_loss = 0.0\n",
    "valid_acc = 0.0\n",
    "timer = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model checkpoint\n",
    "# # Uncomment the cell to resume training the model\n",
    "# # Else the model training will be reset\n",
    "# checkpoint = torch.load(\"models/model_resumable.pth\")\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# current_epoch = checkpoint[\"current_epoch\"]\n",
    "# train_loss = checkpoint[\"train_loss\"]\n",
    "# valid_loss = checkpoint[\"valid_loss\"]\n",
    "# valid_acc = checkpoint[\"valid_acc\"]\n",
    "# timer = checkpoint[\"timer\"]\n",
    "\n",
    "# # Print the metrics of the final epoch of the last training session\n",
    "# print((\"Epoch {}: Training Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.2f}%, Time: {:.2f}s\"\n",
    "# ).format((current_epoch), train_loss, valid_loss, valid_acc, timer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs for the current training session\n",
    "num_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 0.0319, Validation Loss: 0.0021, Accuracy: 99.02%, Time: 1618.72s\n",
      "Epoch 2: Training Loss: 0.0083, Validation Loss: 0.0010, Accuracy: 99.49%, Time: 1734.27s\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Required epoch upto which to train\n",
    "required_epoch = num_epoch + current_epoch\n",
    "\n",
    "# Model training\n",
    "for epoch in range(current_epoch, required_epoch):\n",
    "    # Initialize the metrics\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training step\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        # Move the data to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weigths every other iteration\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute the training loss\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation step\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Disable gradients\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            # Move the data to the device\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute the validation loss\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # Compute the accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            valid_acc += (preds == labels).sum().item()\n",
    "\n",
    "    # End time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Execution time\n",
    "    timer = end_time - start_time\n",
    "        \n",
    "    # Compute the average training loss and validation loss, and accuracy percentage\n",
    "    train_loss /= len(train_data)\n",
    "    valid_loss /= len(valid_data)\n",
    "    valid_acc = (valid_acc / len(valid_data))*100\n",
    "\n",
    "    # Print the metrics of the current epoch of the current training session\n",
    "    print((\"Epoch {}: Training Loss: {:.4f}, Validation Loss: {:.4f}, Accuracy: {:.2f}%, Time: {:.2f}s\"\n",
    "    ).format((epoch + 1), train_loss, valid_loss, valid_acc, timer))\n",
    "\n",
    "# Update current epoch\n",
    "current_epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"models/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model(complete)\n",
    "torch.save(model, \"models/model_complete.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model(resumable)\n",
    "torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"current_epoch\": current_epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"valid_loss\": valid_loss,\n",
    "            \"valid_acc\": valid_acc,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"timer\": timer\n",
    "            }, \"models/model_resumable.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to TorchScript(script)\n",
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save(\"models/model_scripted.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to TorchScript(trace)\n",
    "example_input = torch.rand((1,) + tuple(shape))\n",
    "example_input = example_input.to(device)\n",
    "with torch.jit.optimized_execution(True):\n",
    "    model_traced = torch.jit.trace(model, example_input)\n",
    "model_traced.save(\"models/model_traced.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a9cc220b9cb0ba669dd77126ab318e5eaa86284bb96bc8faa647305984f7ded"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
